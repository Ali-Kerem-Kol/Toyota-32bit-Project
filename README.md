# Toyota 32bit Project

Bu proje; Ã§oklu platformlardan (TCP & REST) dÃ¶viz kuru verilerini toplayan, filtreleyen, dinamik JavaScript ile hesaplayan ve sonuÃ§larÄ± Kafka Ã¼zerinden PostgreSQL ve Elasticsearch'e aktaran, gerÃ§ek zamanlÄ±, mikroservis tabanlÄ± bir backend Ã§Ã¶zÃ¼mÃ¼dÃ¼r.
Veri iÅŸleme, Redis Ã¼zerinde aktif/pasif veri yÃ¶netimiyle yapÄ±lÄ±r ve merkezi loglama & izleme iÃ§in Log4j2 + Filebeat + Kibana kullanÄ±lÄ±r.


---

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

- **Java**
- **Spring Boot**
- **Redis & Redis Stream**
- **Apache Kafka**
- **PostgreSQL**
- **ElasticSearch & Kibana**
- **Log4j2 + Filebeat**
- **Docker & Docker Compose**
- **Javascript**

---

## ğŸ§± Proje Mimarisi

![Proje Mimarisi](Toyota32bitProje/Mimari.png)
Mimari bileÅŸenler:
- `TCPProvider`, `RESTProvider`: FarklÄ± kaynaklardan veri toplar
- `RedisService`: Ara bellek yapÄ±sÄ± (Redis) ile iletiÅŸime geÃ§er
- `FilterService`: Gelen verileri anomaliye karÅŸÄ± denetler.
- `RateCalculatorService + DynamicFormulaService + Formula.js`: Hesaplama akÄ±ÅŸÄ±
- `KafkaProducerService`: Hesaplanan verileri Kafka'ya gÃ¶nderir
- `consumer-postgresql`, `consumer-elasticsearch`: Kafka'dan veri okuyup veritabanlarÄ±na yazar
- `Log4j2 + Filebeat`: JSON loglama ve merkezi izleme
---

## ğŸš€ Kurulum

1. **Repository'yi klonlayÄ±n:**

```bash
git clone https://github.com/Ali-Kerem-Kol/Toyota-32bit-Project.git
cd Toyota-32bit-Project
```

2. **Docker ile Ã§alÄ±ÅŸtÄ±rÄ±n:**

```bash
docker-compose up --build
```

## âš™ï¸ KonfigÃ¼rasyon DosyalarÄ± AÃ§Ä±klamalarÄ±

| Dosya Yolu | AÃ§Ä±klama |
|------------|----------|
| `Main/coordinator/config/config.json` | Ana **Coordinator** yapÄ±landÄ±rmasÄ±: Redis & Kafka baÄŸlantÄ± bilgileri, aktif filtre listesi, `Formula.js` dosya yolu vb. |
| `Main/coordinator/config/rest-config.json` | **RESTProvider** parametreleri |
| `Main/coordinator/config/tcp-config.json` | **TCPProvider** parametreleri |
| `Main/coordinator/config/jumpThresholdFilter.json` | **JumpThresholdFilter** parametreleri |
| `Servers/RESTServer/config/config.json` | **RESTServer**â€™ simÃ¼lasyon parametreleri |
| `Servers/TCPServer/config/config.json` | **TCPServer** simÃ¼lasyon parametreleri |
| `Consumers/consumer-postgresql/src/main/resources/application.properties` | **consumer-postgresql** Spring Boot ayar dosyasÄ± â€“ PostgreSQL, Kafka bilgisi. |
| `Consumers/consumer-elasticsearch/src/main/resources/application.properties` | **consumer-elasticsearch** Spring Boot ayar dosyasÄ± â€“ Elasticsearch, Kafka bilgisi. |
| `filebeat.yml` | Filebeat giriÅŸ/Ã§Ä±kÄ±ÅŸ ayarlarÄ±: Log yollarÄ± ve Elasticsearch hedefi. |





---

## ğŸ“‚ KlasÃ¶r YapÄ±sÄ±

```
Toyota32bitProje/
â”‚
â”œâ”€â”€ Project/
â”‚   â”œâ”€â”€ Consumers/
â”‚   â”‚   â””â”€â”€ consumer-elasticsearch
â”‚   â”‚   â””â”€â”€ consumer-postgresql
â”‚   â”œâ”€â”€ Main/
â”‚   â”‚   â””â”€â”€ coordinator
â”‚   â”œâ”€â”€ Servers/
â”‚   â”‚   â””â”€â”€ RESTServer
â”‚   â”‚   â””â”€â”€ TCPServer
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ filebeat.yml
â”‚
â”œâ”€â”€ Proje Teknik DokÃ¼manÄ± V0.1.docx
â”œâ”€â”€ Mimari.png
```

## ğŸ’¡ KÄ±sa AkÄ±ÅŸ Ã–zeti

1. **Veri SaÄŸlayÄ±cÄ±lar (TCPProvider & RESTProvider)**
   - FarklÄ± platformlardan gerÃ§ek zamanlÄ± dÃ¶viz kuru verileri toplar.
   - Veriler filtrelenir ve Redisâ€™e (raw_rates) gÃ¶nderilir.

2. **Coordinator (Ana Uygulama)**
   - Redis'ten en gÃ¼ncel aktif raw rates'leri Ã§eker.
   - Hesaplamalar yapÄ±lÄ±r ve kullanÄ±lan veriler tekrar kullanÄ±lmamak Ã¼zere pasiflenir.
   - Hesaplanan veriler Redisâ€™te calculated_rates olarak saklanÄ±r.
   - Redis'ten en gÃ¼ncel aktif calculated rates'leri Ã§eker.
   - SonuÃ§lar Kafkaâ€™ya gÃ¶nderilir ve kullanÄ±lan veriler tekrar kullanÄ±lmamak Ã¼zere pasiflenir.

3. **Kafka**
   - Hesaplanan verileri ilgili tÃ¼ketici servislere daÄŸÄ±tÄ±r.

4. **Consumer-PostgreSQL & Consumer-Elasticsearch**
   - Kafkaâ€™dan gelen verileri kendi veritabanÄ±na (PostgreSQL, Elasticsearch) yazar.

5. **Loglama & Ä°zleme**
   - TÃ¼m servisler Log4j2 ile JSON formatÄ±nda log tutar.
   - Filebeat, loglarÄ± merkezi olarak Elastic/Kibanaâ€™ya yÃ¶nlendirir.


---

# ğŸ§  Redis (Raw & Calculated Rate Ä°zleme)

Uygulama, veri Ã¶nbellekleme ve pasif/aktif yÃ¶netim iÅŸlemlerini `Redis` Ã¼zerinden yÃ¼rÃ¼tÃ¼r. Redis iÃ§erisinde iki ana stream kullanÄ±lÄ±r:

- `raw_rates`: Platformlardan gelen ham veriler (aktif/pasif olarak iÅŸaretlenmiÅŸ)
- `calculated_rates`: Hesaplama motorundan Ã§Ä±kan sonuÃ§lar (aktif/pasif olarak iÅŸaretlenmiÅŸ)

### ğŸ”Œ Redis'e BaÄŸlanmak

Redis'e CLI Ã¼zerinden baÄŸlanmak iÃ§in:

```bash
docker exec -it redis redis-cli
```

Verileri gÃ¶rmek iÃ§in Ã¶rnek komutlar:
```bash
LRANGE raw_rates:TCP_PLATFORM:EURUSD 0 10
LRANGE calculated_rates:EURTRY 0 10
```
Pasif hale getirilen veriler isActive=false olarak iÅŸaretlenir.


# ğŸ—ƒï¸ PgAdmin (PostgreSQL ArayÃ¼zÃ¼)

Kafkaâ€™dan gelen hesaplanmÄ±ÅŸ veriler, `consumer-postgresql` servisi tarafÄ±ndan PostgreSQL veritabanÄ±na yazÄ±lÄ±r. Bu verileri incelemek iÃ§in web arayÃ¼zÃ¼ olan **PgAdmin** kullanÄ±labilir.

### ğŸŒ EriÅŸim Bilgileri

- **URL:** http://localhost:8083
- **E-posta:** `admin@admin.com`
- **Åifre:** `admin`

### ğŸ—„ï¸ BaÄŸlantÄ± Kurulumu

PgAdmin arayÃ¼zÃ¼ne girdikten sonra veritabanÄ±na baÄŸlanmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin:

1. Sol Ã¼stten **"Servers > Register > Server..."** seÃ§eneÄŸini tÄ±klayÄ±n.
2. **General sekmesinde:**
   - **Name:** `postgres-db`
3. **Connection sekmesinde:**
   - **Host name/address:** `postgres-db`
   - **Port:** `5432`
   - **Username:** `postgres`
   - **Password:** `1234`

4. Kaydettikten sonra sol menÃ¼de `exchange_rates` adlÄ± veritabanÄ±nÄ± gÃ¶receksiniz.
   - Ä°Ã§erisinde `tbl_rates` tablosu yer alÄ±r.
   - Bu tabloda hesaplanmÄ±ÅŸ dÃ¶viz kuru verileri yer alÄ±r.

PgAdmin sayesinde gelen verilerin doÄŸruluÄŸunu manuel olarak kontrol edebilirsiniz.


# âš™ï¸ YapÄ±landÄ±rma DosyalarÄ±

## ğŸ“ `Main/coordinator/config/config.json`
Ana uygulamanÄ±n tÃ¼m konfigÃ¼rasyonlarÄ±nÄ± iÃ§erir:

- **Veri saÄŸlayÄ±cÄ±lar:** `TCPProvider`, `RESTProvider`
- **Hesaplama:** JavaScript dosyasÄ± Ã¼zerinden dinamik hesaplama (`Formula.js`)
- **Kafka ayarlarÄ±:** Broker adresi, topic adÄ±, retry/reinit deÄŸerleri
- **Redis cache ayarlarÄ±:** TTL, max liste boyutu
- **Filtre tanÄ±mlarÄ±:** `JumpThresholdFilter` filtresi platform-bazlÄ± tanÄ±mlÄ±dÄ±r

> Ã–rnek:
```json
"subscribeRates": ["USDTRY", "EURUSD", "GBPUSD"],
"formulaFilePath": "/app/Main/coordinator/scripts/Formula.js",
"redis": {
  "host": "redis",
  "port": 6379,
  "ttlSeconds": 10,
  "maxListSize": 10
}
```

---

## ğŸŒ SaÄŸlayÄ±cÄ± Platform KonfigÃ¼rasyonlarÄ±

### ğŸ“„ `tcp-config.json`
TCP sunucusuna baÄŸlanacak host ve port bilgileri:

```json
{
  "host": "tcp-server",
  "port": "5000"
}
```

### ğŸ“„ `rest-config.json`
REST sunucusunun API endpointâ€™i ve API anahtarÄ±:

```json
{
  "restApiUrl": "http://rest-server:8081/api/rates",
  "apiKey": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
  "pollInterval": "1"
}
```

### ğŸ“„ `jumpThresholdFilter.json`
JumpThreshold filtresinin eÅŸik deÄŸeri (%):

```json
{
  "maxJumpPercent": 0.36
}
```

---

## ğŸ§ª SimÃ¼lasyon SaÄŸlayÄ±cÄ± BaÅŸlangÄ±Ã§ Verileri

### ğŸ“„ `Servers/RESTServer/config.json`
REST sunucusu ilk kurlar:

```json
{
  "apiKey": "8f5d3c9a-94b0-49d4-87e9-12a5c13e6c7a",
  "initialRates": {
    "USDTRY": 34.50,
    "EURUSD": 1.08,
    "GBPUSD": 1.25
  }
}
```

### ğŸ“„ `Servers/TCPServer/config.json`
TCP sunucusu ilk kurlar ve yayÄ±n frekansÄ± (ms):

```json
{
  "initialRates": {
    "USDTRY": 34.0,
    "EURUSD": 1.05,
    "GBPUSD": 1.25
  },
  "publishFrequency": 1000
}
```

---

## ğŸ§¾ Consumer â€“ PostgreSQL

### ğŸ“„ `application.properties`
- **VeritabanÄ± baÄŸlantÄ±sÄ±**
- **Kafka yapÄ±landÄ±rmasÄ±**
- **JPA ayarlarÄ±**

```properties
spring.datasource.url=jdbc:postgresql://postgres-db:5432/exchange_rates
spring.kafka.bootstrap-servers=kafka:9092
spring.kafka.consumer.group-id=ratesConsumerGroup-pg
spring.kafka.topic=rates-topic
```

---

## ğŸ“¡ Consumer â€“ Elasticsearch

### ğŸ“„ `application.properties`
- **Elasticsearch hedef URI ve index**
- **Kafka consumer ayarlarÄ±**

```properties
spring.elasticsearch.uris=http://elasticsearch:9200
spring.elasticsearch.index=rates_index
spring.kafka.consumer.group-id=ratesConsumerGroup-es
consumer.kafka.topic=rates-topic
```

---

## ğŸ“¦ Filebeat â€“ Log YÃ¶nlendirme

### ğŸ“„ `filebeat.yml`
Bu yapÄ±landÄ±rma sayesinde Ã¼Ã§ farklÄ± servisin JSON log dosyalarÄ± okunarak Elasticsearch'e gÃ¶nderilir.

- `coordinator`, `consumer-postgresql`, `consumer-elasticsearch` log klasÃ¶rleri dinlenir
- `message` alanÄ± iÃ§indeki JSON Ã§Ã¶zÃ¼lerek `log.level`, `loggerName` gibi alanlar Ã§Ä±karÄ±lÄ±r
- Loglar index olarak ÅŸu formatta gelir:  
  ```
  logs-coordinator-2025.06.08
  logs-consumer-postgresql-2025.06.08
  logs-consumer-elasticsearch-2025.06.08
  ```

```yaml
filebeat.inputs:
  - type: filestream
    paths: [ "/app/Main/coordinator/logs/*.json" ]
    json.keys_under_root: true
    processors:
      - decode_json_fields:
          fields: ["message"]
          overwrite_keys: true

output.elasticsearch:
  hosts: ["http://elasticsearch:9200"]
  index: "logs-%{[fields.service]}-%{+yyyy.MM.dd}"
setup.kibana:
  host: "kibana:5601"
```

# ğŸ“Š Loglama ve Ä°zleme (Kibana)

### ğŸ“‚ Log FormatÄ± ve YapÄ±sÄ±

Uygulama servisleri, `Log4j2` kullanarak loglarÄ±nÄ± **JSON formatÄ±nda** `.json` uzantÄ±lÄ± dosyalara yazar. Her servis kendi loglarÄ±nÄ± ÅŸu klasÃ¶rlere yazar:

- `coordinator`: `Main/coordinator/logs/coordinator.json`
- `consumer-postgresql`: `Consumers/consumer-postgresql/logs/consumer-postgresql.json`
- `consumer-elasticsearch`: `Consumers/consumer-elasticsearch/logs/consumer-elasticsearch.json`

YalnÄ±zca `INFO` ve Ã¼zeri seviyedeki loglar dosyaya yazÄ±lÄ±rken, konsola `TRACE` seviyesine kadar tÃ¼m loglar gÃ¶nderilir. Dosyalar gÃ¼nlÃ¼k olarak dÃ¶ner (`RollingFile`).

### ğŸ” Filebeat ile Log Toplama

`filebeat.yml` yapÄ±landÄ±rmasÄ±, bu log dosyalarÄ±nÄ± okuyarak `Elasticsearch`'e gÃ¶nderir. Her log, `message` alanÄ± iÃ§inde gÃ¶mÃ¼lÃ¼ bir JSON iÃ§erdiÄŸinden, `decode_json_fields` ile bu alan ayrÄ±ÅŸtÄ±rÄ±lÄ±r.

### ğŸ§  Elasticsearch Index YapÄ±sÄ±

Filebeat loglarÄ± ÅŸu formattaki index'lere yollar:
- logs-coordinator-2025.06.08
- logs-consumer-postgresql-2025.06.08
- logs-consumer-elasticsearch-2025.06.08


### ğŸ“¥ Kibana'ya EriÅŸim

Kibana servisine eriÅŸmek iÃ§in tarayÄ±cÄ±nÄ±zdan ÅŸu adrese gidin: `http://localhost:5601`

Ä°lk defa aÃ§Ä±ldÄ±ÄŸÄ±nda index pattern oluÅŸturmanÄ±z gerekir:

1. Sol menÃ¼den **Stack Management > Index Patterns** yolunu izleyin.
2. Yeni bir index pattern oluÅŸturun: `logs-*`
3. Zaman filtresi olarak `@timestamp` alanÄ±nÄ± seÃ§in.
4. **Discover** sekmesinde `level`, `loggerName`, `message`, `service`, `timestamp` gibi alanlarÄ± gÃ¶rebilirsiniz.

### ğŸ“ GeliÅŸmiÅŸ Ä°zleme

Her servisin loglarÄ±nda hata, uyarÄ±, bilgi ve izleme detaylarÄ± (trace) ayrÄ± seviyelerde gÃ¶rÃ¼lebilir. Ã–rneÄŸin:

- `INFO`: BaÅŸarÄ±yla veri Kafka'ya gÃ¶nderildi
- `ERROR`: Redis baÄŸlantÄ± hatasÄ±
- `DEBUG`: Filtrelenen veri detaylarÄ±
- `TRACE`: Uygulama iÃ§i dÃ¼ÅŸÃ¼k seviye iÅŸlem detaylarÄ±

Bu yapÄ± sayesinde **gerÃ§ek zamanlÄ± log izleme** ve **hata ayÄ±klama** iÅŸlemleri profesyonelce yapÄ±labilir.
---


## âœ‰ï¸ Ä°letiÅŸim
- Proje Sahibi : Ali Kerem Kol
- E-posta : ali_.kerem@hotmail.com
